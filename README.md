
<p align="center" width="100%">
<a target="_blank"><img src="./facebook_cover_photo_2[1].png" alt="xinghan" style="width: 100%; min-width: 500px; display: block; margin: auto;"></a>
</p>



<div style='display:flex; gap: 0.25rem; '>
<a href='https://arxiv.org/abs/2407.08965'><img src='https://img.shields.io/badge/Paper-PDF-arxiv'></a>
</div>


##  目录

- [🎉 新闻](#新闻)
- [📖 模型介绍](#模型介绍)
- [📊 评测表现 🥇🥇🔥🔥](#评测表现)
- [🎥 可视化](#可视化)
- [🛠️ 快速使用](#快速使用)
- [📜 协议、引用、致谢](#协议引用)
<br><br>



## <a name="新闻"></a>🎉 新闻
- <h3> [2024.07.03] 🚀🚀 Our paper 'Lite-SAM' has been accepted by ECCV 2024, with a high score of 544. ! <br>感谢 CVer公众号的宣传:  https://zhuanlan.zhihu.com/p/708992208 </h3>
![image](https://github.com/user-attachments/assets/b359778f-0234-4790-a968-d06b0b2eada0)
- <h3> [2024.07.05] ⭐️  Our new paper XSAM-v1 is coming .
- <h3> [2024.08.30] 🚀🚀 Our new project Yoloworld-plus will be coming .


## 项目特色

- **多种模型**：工业和学术结合，一切以落地为基础的研究。


## 性能指标


## 引用

如果您觉得此项目有帮助，请考虑以下列格式引用

```bibtex
@article{fu2024lite,
  title={Lite-SAM Is Actually What You Need for Segment Everything},
  author={Fu, Jianhai and Yu, Yuanjie and Li, Ningchuan and Zhang, Yi and Chen, Qichao and Xiong, Jianping and Yin, Jun and Xiang, Zhiyu},
  journal={arXiv preprint arXiv:2407.08965},
  publisher={ECCV2024},
  year={2024}
}
```

## 致谢

感谢以上诸位作者的付出。

